"""
XSMN Crawler - Crawl k·∫øt qu·∫£ x·ªï s·ªë mi·ªÅn Nam
Ngu·ªìn: xskt.com.vn (c√≥ th·ªÉ thay ƒë·ªïi)
"""

import requests
from bs4 import BeautifulSoup
from datetime import datetime, date
from typing import Optional, Dict, List
import time


class XSMNCrawler:
    """Crawler cho x·ªï s·ªë mi·ªÅn Nam"""
    
    BASE_URL = "https://xskt.com.vn/xsmn"
    BACKUP_URL = "https://www.minhngoc.net.vn/xo-so-mien-nam"
    
    def __init__(self):
        """Initialize crawler v·ªõi headers"""
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) '
                         'AppleWebKit/537.36 (KHTML, like Gecko) '
                         'Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'vi-VN,vi;q=0.9,en-US;q=0.8,en;q=0.7',
        }
    
    def fetch_results(self, target_date: date, province: str = "tp-hcm") -> Optional[Dict]:
        """
        Crawl k·∫øt qu·∫£ XSMN cho ng√†y c·ª• th·ªÉ
        
        Args:
            target_date: Ng√†y c·∫ßn crawl
            province: T·ªânh/th√†nh (m·∫∑c ƒë·ªãnh TP.HCM v√¨ quay h√†ng ng√†y)
        
        Returns:
            Dictionary ch·ª©a k·∫øt qu·∫£ ho·∫∑c None
        """
        print(f"üîç Crawling XSMN ({province}) for {target_date}...")
        
        try:
            results = self._crawl_from_xskt(target_date, province)
            
            if results:
                print(f"‚úÖ Successfully crawled XSMN")
                return results
            
            print(f"‚ùå Failed to crawl XSMN")
            return None
            
        except Exception as e:
            print(f"‚ùå Error crawling XSMN: {e}")
            return None
    
    def _crawl_from_xskt(self, target_date: date, province: str) -> Optional[Dict]:
        """
        Crawl t·ª´ xskt.com.vn
        
        L∆ØU √ù: C·∫•u tr√∫c t∆∞∆°ng t·ª± XSMB nh∆∞ng c√≥ th·ªÉ kh√°c selectors
        """
        try:
            date_str = target_date.strftime("%d-%m-%Y")
            url = f"{self.BASE_URL}/{province}/{date_str}.html"
            
            print(f"  ‚Üí Fetching: {url}")
            
            response = requests.get(url, headers=self.headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Parse k·∫øt qu·∫£ (t∆∞∆°ng t·ª± XSMB)
            results = {
                'draw_date': target_date,
                'region': 'XSMN',
                'special_prize': self._extract_prize(soup, 'special'),
                'first_prize': self._extract_prize(soup, 'first'),
                'second_prize': self._extract_prize_array(soup, 'second', 1),
                'third_prize': self._extract_prize_array(soup, 'third', 2),
                'fourth_prize': self._extract_prize_array(soup, 'fourth', 7),
                'fifth_prize': self._extract_prize_array(soup, 'fifth', 1),
                'sixth_prize': self._extract_prize_array(soup, 'sixth', 3),
                'seventh_prize': self._extract_prize_array(soup, 'seventh', 1),
            }
            
            if results['special_prize']:
                return results
            else:
                print(f"  ‚ö†Ô∏è No special prize found")
                return None
                
        except Exception as e:
            print(f"  ‚ùå Error: {e}")
            return None
    
    def _extract_prize(self, soup: BeautifulSoup, prize_type: str) -> Optional[str]:
        """Extract m·ªôt gi·∫£i th∆∞·ªüng ƒë∆°n"""
        try:
            if prize_type == 'special':
                elem = soup.select_one('.special-prize .number')
            elif prize_type == 'first':
                elem = soup.select_one('.first-prize .number')
            else:
                return None
            
            if elem:
                return elem.text.strip()
            return None
            
        except Exception as e:
            return None
    
    def _extract_prize_array(
        self, 
        soup: BeautifulSoup, 
        prize_type: str, 
        expected_count: int
    ) -> List[str]:
        """Extract c√°c gi·∫£i c√≥ nhi·ªÅu s·ªë"""
        try:
            selector_map = {
                'second': '.second-prize .number',
                'third': '.third-prize .number',
                'fourth': '.fourth-prize .number',
                'fifth': '.fifth-prize .number',
                'sixth': '.sixth-prize .number',
                'seventh': '.seventh-prize .number',
            }
            
            selector = selector_map.get(prize_type)
            if not selector:
                return []
            
            elements = soup.select(selector)
            numbers = [elem.text.strip() for elem in elements]
            
            return numbers
            
        except Exception as e:
            return []


if __name__ == "__main__":
    from datetime import timedelta
    
    crawler = XSMNCrawler()
    yesterday = date.today() - timedelta(days=1)
    
    print(f"\nTesting XSMN Crawler\n{'='*60}\n")
    
    results = crawler.fetch_results(yesterday)
    
    if results:
        print(f"\n‚úÖ Success! Special Prize: {results['special_prize']}")
    else:
        print(f"\n‚ùå Failed - need to update selectors")
