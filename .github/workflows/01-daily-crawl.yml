name: 01 - Daily Lottery Crawl

# Ch·∫°y h√†ng ng√†y l√∫c 19:00 GMT+7 (12:00 UTC)
on:
  schedule:
    - cron: '0 12 * * *'  # 19:00 GMT+7
  workflow_dispatch:  # Cho ph√©p ch·∫°y th·ªß c√¥ng

jobs:
  crawl-xsmb:
    name: Crawl XSMB
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Crawl XSMB Results
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          python -c "
          from src.crawler.xsmb_crawler import XSMBCrawler
          from src.database.supabase_client import LotteryDB
          from datetime import datetime, timedelta
          
          print('üöÄ Starting XSMB crawler...')
          
          crawler = XSMBCrawler()
          db = LotteryDB()
          
          # Use Vietnam Time (UTC+7)
          vn_time = datetime.utcnow() + timedelta(hours=7)
          today = vn_time.date()
          print(f'Current Vietnam Time: {vn_time}')
          
          results = crawler.fetch_results(today)
          
          if results:
              try:
                  db.upsert_draw(results)
                  
                  # Log success
                  db.log_crawler_status({
                      'crawl_date': today,
                      'region': 'XSMB',
                      'status': 'success',
                      'records_inserted': 1
                  })
                  
                  print('‚úÖ XSMB crawl successful!')
                  print(f'   Date: {today}')
                  print(f'   Special Prize: {results[\"special_prize\"]}')
                  
              except Exception as e:
                  # Log error
                  db.log_crawler_status({
                      'crawl_date': today,
                      'region': 'XSMB',
                      'status': 'failed',
                      'error_message': str(e),
                      'records_inserted': 0
                  })
                  print(f'‚ùå Error saving to database: {e}')
                  exit(1)
          else:
              # Log failure
              db.log_crawler_status({
                  'crawl_date': today,
                  'region': 'XSMB',
                  'status': 'failed',
                  'error_message': 'Crawler returned no results',
                  'records_inserted': 0
              })
              print('‚ùå XSMB crawl failed - no results')
              exit(1)
          "
  
  crawl-xsmn:
    name: Crawl XSMN
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Crawl XSMN Results
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          python -c "
          from src.crawler.xsmn_crawler import XSMNCrawler
          from src.database.supabase_client import LotteryDB
          from datetime import datetime, timedelta
          
          print('üöÄ Starting XSMN crawler...')
          
          crawler = XSMNCrawler()
          db = LotteryDB()
          
          
          # Use Vietnam Time (UTC+7)
          vn_time = datetime.utcnow() + timedelta(hours=7)
          today = vn_time.date()
          print(f'Current Vietnam Time: {vn_time}')
          
          # Crawl XSMN for ALL provinces today
          provinces = crawler.get_provinces_for_date(today)
          print(f'   Target provinces: {provinces}')
          
          success_count = 0
          
          for province in provinces:
              try:
                  print(f'   Crawling {province}...')
                  results = crawler.fetch_results(today, province=province)
                  
                  if results:
                      # D√πng upsert ƒë·ªÉ tr√°nh l·ªói duplicate n·∫øu ch·∫°y l·∫°i
                      db.upsert_draw(results)
                      success_count += 1
                      print(f'   ‚úÖ {province} success!')
                  else:
                      print(f'   ‚ö†Ô∏è {province} no data')
                      
              except Exception as e:
                  print(f'   ‚ùå Error {province}: {e}')

          if success_count > 0:
              # Log overall success if at least one province succeeded
              db.log_crawler_status({
                  'crawl_date': today,
                  'region': 'XSMN',
                  'status': 'success',
                  'records_inserted': success_count,
                  'error_message': f'Crawled {success_count}/{len(provinces)} provinces'
              })
              print(f'‚úÖ XSMN crawl completed: {success_count}/{len(provinces)} success')
          else:
              # Log failure if ALL failed
              db.log_crawler_status({
                  'crawl_date': today,
                  'region': 'XSMN',
                  'status': 'failed',
                  'error_message': 'No data found for any province',
                  'records_inserted': 0
              })
              print('‚ùå XSMN crawl failed - no results for any province')
              exit(1)
          "
