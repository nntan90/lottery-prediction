name: 01 - Daily Lottery Crawl

# Ch·∫°y h√†ng ng√†y l√∫c 19:00 GMT+7 (12:00 UTC)
on:
  schedule:
    - cron: '0 12 * * *'  # 19:00 GMT+7
  workflow_dispatch:  # Cho ph√©p ch·∫°y th·ªß c√¥ng

jobs:
  crawl-xsmb:
    name: Crawl XSMB
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Crawl XSMB Results
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: |
          python -c "
          import asyncio
          from src.crawler.xsmb_crawler import XSMBCrawler
          from src.database.supabase_client import LotteryDB
          from src.bot.telegram_bot import LotteryNotifier
          from datetime import datetime, timedelta
          
          async def main():
              print('üöÄ Starting XSMB crawler...')
              
              crawler = XSMBCrawler()
              db = LotteryDB()
              try:
                  bot = LotteryNotifier()
              except Exception as e:
                  print(f'‚ö†Ô∏è Could not init bot: {e}')
                  bot = None
              
              # Use Vietnam Time (UTC+7)
              vn_time = datetime.utcnow() + timedelta(hours=7)
              today = vn_time.date()
              print(f'Current Vietnam Time: {vn_time}')
              
              try:
                  results = crawler.fetch_results(today)
                  
                  if results:
                      db.upsert_draw(results)
                      
                      # Log success
                      db.log_crawler_status({
                          'crawl_date': today,
                          'region': 'XSMB',
                          'status': 'success',
                          'records_inserted': 1
                      })
                      
                      msg = f'‚úÖ <b>Crawl XSMB Success</b>\nüìÖ {today}\nüèÜ ƒêB: {results[\"special_prize\"]}'
                      print(msg)
                      if bot: await bot.send_message(msg)
                      
                  else:
                      error_msg = 'Crawler returned no results'
                      # Log failure
                      db.log_crawler_status({
                          'crawl_date': today,
                          'region': 'XSMB',
                          'status': 'failed',
                          'error_message': error_msg,
                          'records_inserted': 0
                      })
                      print(f'‚ùå {error_msg}')
                      if bot: await bot.send_error_alert(f'XSMB Crawl Failed: {error_msg}')
                      exit(1)
                      
              except Exception as e:
                  error_msg = str(e)
                  # Log error
                  db.log_crawler_status({
                      'crawl_date': today,
                      'region': 'XSMB',
                      'status': 'failed',
                      'error_message': error_msg,
                      'records_inserted': 0
                  })
                  print(f'‚ùå Error: {e}')
                  if bot: await bot.send_error_alert(f'XSMB Crawl Error: {e}')
                  exit(1)

          if __name__ == '__main__':
              asyncio.run(main())
          "
  
  crawl-xsmn:
    name: Crawl XSMN
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Crawl XSMN Results
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: |
          python -c "
          import asyncio
          from src.crawler.xsmn_crawler import XSMNCrawler
          from src.database.supabase_client import LotteryDB
          from src.bot.telegram_bot import LotteryNotifier
          from datetime import datetime, timedelta
          
          async def main():
              print('üöÄ Starting XSMN crawler...')
              
              crawler = XSMNCrawler()
              db = LotteryDB()
              try:
                  bot = LotteryNotifier()
              except Exception as e:
                  print(f'‚ö†Ô∏è Could not init bot: {e}')
                  bot = None
              
              # Use Vietnam Time (UTC+7)
              vn_time = datetime.utcnow() + timedelta(hours=7)
              today = vn_time.date()
              print(f'Current Vietnam Time: {vn_time}')
              
              # Crawl XSMN for ALL provinces today
              provinces = crawler.get_provinces_for_date(today)
              print(f'   Target provinces: {provinces}')
              
              success_count = 0
              
              for province in provinces:
                  try:
                      print(f'   Crawling {province}...')
                      results = crawler.fetch_results(today, province=province)
                      
                      if results:
                          # D√πng upsert ƒë·ªÉ tr√°nh l·ªói duplicate n·∫øu ch·∫°y l·∫°i
                          db.upsert_draw(results)
                          success_count += 1
                          print(f'   ‚úÖ {province} success!')
                      else:
                          print(f'   ‚ö†Ô∏è {province} no data')
                          
                  except Exception as e:
                      print(f'   ‚ùå Error {province}: {e}')

              if success_count > 0:
                  # Log overall success if at least one province succeeded
                  db.log_crawler_status({
                      'crawl_date': today,
                      'region': 'XSMN',
                      'status': 'success',
                      'records_inserted': success_count,
                      'error_message': f'Crawled {success_count}/{len(provinces)} provinces'
                  })
                  
                  msg = f'‚úÖ <b>Crawl XSMN Success</b>\nüìÖ {today}\nüìä Updated: {success_count}/{len(provinces)} provinces'
                  print(msg)
                  if bot: await bot.send_message(msg)
                  
              else:
                  error_msg = 'No data found for any province'
                  # Log failure if ALL failed
                  db.log_crawler_status({
                      'crawl_date': today,
                      'region': 'XSMN',
                      'status': 'failed',
                      'error_message': error_msg,
                      'records_inserted': 0
                  })
                  print(f'‚ùå {error_msg}')
                  if bot: await bot.send_error_alert(f'XSMN Crawl Failed: {error_msg}')
                  exit(1)

          if __name__ == '__main__':
              asyncio.run(main())
          "
  verify-results:
    name: Verify Predictions
    needs: [crawl-xsmb, crawl-xsmn]
    runs-on: ubuntu-latest
    if: always() # Run even if one crawl fails (to verify what succeeded)
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Verify Predictions vs Results
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: |
          python src/scripts/verify_predictions.py
